{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WK09 Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/data_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from data_utils import StandardScaler\n",
    "from data_utils import object_from_json_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification / Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Load Dataset\n",
    "WINE_FILE = \"https://raw.githubusercontent.com/DM-GY-9103-2024F-H/9103-utils/main/datasets/json/wines.json\"\n",
    "\n",
    "# Read into DataFrame\n",
    "wines_data = object_from_json_url(WINE_FILE)\n",
    "wines_df = pd.DataFrame.from_records(wines_data)\n",
    "\n",
    "## 3. Normalize\n",
    "wine_scaler = StandardScaler()\n",
    "wines_scaled = wine_scaler.fit_transform(wines_df)\n",
    "\n",
    "features = wines_scaled.drop(columns=[\"quality\"])\n",
    "wines_scaled.cov()[\"quality\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_pca = PCA()\n",
    "wines_pcad = wine_pca.fit_transform(features.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = features[\"alcohol\"].values\n",
    "y = features[\"density\"].values\n",
    "c = [colors[int(i)] for i in wines_scaled[\"quality\"].values]\n",
    "\n",
    "plt.scatter(x, y, color=c, marker='o', linestyle='', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = wines_pcad[:, 0]\n",
    "y = wines_pcad[:, 1]\n",
    "c = [colors[int(i)] for i in wines_scaled[\"quality\"].values]\n",
    "\n",
    "# Plot the PCAs\n",
    "plt.scatter(x, y, color=c, marker='o', linestyle='', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "## 5. Create a KMeans object\n",
    "km_model = KMeans(n_clusters=4, n_init=10)\n",
    "\n",
    "# Create a model that tries to group wines by features\n",
    "result = km_model.fit(features.values)\n",
    "\n",
    "## 6. Run the model on the training data\n",
    "predicted_scaled = km_model.predict(features.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = features[\"alcohol\"].values\n",
    "y = features[\"density\"].values\n",
    "c = [colors[i] for i in predicted_scaled]\n",
    "\n",
    "plt.scatter(x, y, color=c, marker='o', linestyle='', alpha=0.5)\n",
    "plt.xlim(-2,3)\n",
    "plt.ylim(-2,3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = wines_pcad[:, 0]\n",
    "y = wines_pcad[:, 1]\n",
    "c = [colors[i] for i in predicted_scaled]\n",
    "\n",
    "# Plot the PCAs\n",
    "plt.scatter(x, y, color=c, marker='o', linestyle='', alpha=0.5)\n",
    "plt.xlim(-4,4)\n",
    "plt.ylim(-4,4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X_reduced = PCA(n_components=3).fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.data[:, 0]\n",
    "y = iris.data[:, 1]\n",
    "c = [colors[int(i)] for i in iris.target]\n",
    "\n",
    "plt.scatter(x, y, color=c, marker='o', linestyle='', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_reduced[:, 0]\n",
    "y = X_reduced[:, 1]\n",
    "c = [colors[int(i)] for i in iris.target]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(9, 6.75), dpi=150)\n",
    "plt.scatter(x, y, color=colors[0], marker='o', linestyle='', alpha=0.7)\n",
    "plt.xlabel(\"petal length\")\n",
    "plt.ylabel(\"petal width\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(9, 6.75), dpi=150)\n",
    "plt.scatter(x, y, color=c, marker='o', linestyle='', alpha=0.7)\n",
    "plt.xlabel(\"petal length\")\n",
    "plt.ylabel(\"petal width\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WK F Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/data_utils.py\n",
    "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/image_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from data_utils import PCA, RandomForestClassifier, StandardScaler, SVC\n",
    "from data_utils import classification_error, object_from_json_url\n",
    "\n",
    "from image_utils import make_image, open_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hilbert Curve\n",
    "\n",
    "- https://pypi.org/project/hilbertcurve/\n",
    "- https://github.com/galtay/hilbertcurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap(v, nmax, nmin):\n",
    "  return ((v - v.min()) / v.ptp()) * (nmax - nmin) + nmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "faces = []\n",
    "\n",
    "for l in range(1, 41):\n",
    "  for i in range(1, 11):\n",
    "    mimg = open_image(f\"./data/imgs/att-faces/s{l}/{i}.pgm\")\n",
    "    faces.append(mimg.pixels)\n",
    "    labels.append(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dim Red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = np.random.normal([0, 0], [1,0.71], size=(500,2))\n",
    "X[:,1] = X[:,0]/1.5 + X[:,1]\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "Xt = pca.fit_transform(X)\n",
    "Xi = pca.inverse_transform(Xt)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], s=2)\n",
    "plt.scatter(X[:,0], [0]*len(X), s=2, c='#7DF9FF')\n",
    "plt.scatter(Xi[:,0], Xi[:,1], s=2, c='r')\n",
    "plt.xlim([-4, 4])\n",
    "plt.ylim([-4, 4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.normal([0, 0, 0], [1, 0.8, 0.8], size=(500, 3))\n",
    "X[:,1] = X[:,0]/1.25 + X[:,1]\n",
    "X[:,2] = X[:,0]/0.80 + X[:,2]\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "Xt = pca.fit_transform(X)\n",
    "Xi = pca.inverse_transform(Xt)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(X[:,0], X[:,1], X[:,2], s=3)\n",
    "ax.scatter(Xi[:,0], Xi[:,1], Xi[:,2], s=3, c='r')\n",
    "ax.set_xlim((-4, 4))\n",
    "ax.set_ylim((-4, 4))\n",
    "ax.set_zlim((-4, 4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "pca3d = [{\"X\":round(x[0],5), \"Y\":round(x[1],5), \"Z\":round(x[2],5)} for x in X]\n",
    "\n",
    "with open(\"./pca3d.json\", \"w\") as f:\n",
    "  json.dump(pca3d, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA as Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame([[8,4,6],[10,6,8],[15,7,13],[20,11,15]], columns=[\"W\",\"L\",\"H\"])\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "X_pca = pca.fit_transform(X_df)\n",
    "\n",
    "print(X_pca.values, \"\\n\\n\", X_df.mean(), \"\\n\\n\", pca.components_)\n",
    "\n",
    "X_pca.values @ pca.components_ + X_df.mean().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATT Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_components=0.80 keeps 80% of the variation\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(faces)\n",
    "\n",
    "print(sum(pca.explained_variance_ratio_))\n",
    "\n",
    "components = pca.components_\n",
    "latent = pca.transform(faces)\n",
    "pfaces = pca.inverse_transform(latent)\n",
    "\n",
    "print(latent.shape, pfaces.shape)\n",
    "\n",
    "for pc in components[:2]:\n",
    "  display(make_image(remap(pc, 0, 255), width=92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(make_image(list(faces[0]), width=92))\n",
    "display(make_image(list(pfaces[0]), width=92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random face\n",
    "fake_latent = np.random.normal(latent.mean(axis=0), latent.std(axis=0)).reshape(1,-1)\n",
    "fake_face = pca.inverse_transform(fake_latent)\n",
    "display(make_image(list(fake_face[0]), width=92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = latent[:,0]\n",
    "y = latent[:,1]\n",
    "z = latent[:,2]\n",
    "ccs = [i for sub in [[v]*10 for v in range(1,41)] for i in sub]\n",
    "\n",
    "plt.scatter(x, y, c=labels, marker='o', linestyle='', alpha=1, cmap=\"tab10\")\n",
    "plt.title(\"Principal Components\")\n",
    "plt.xlabel(\"PC 0\")\n",
    "plt.ylabel(\"PC 1\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(x,y,z, c=labels, marker='o', linestyle='', alpha=1, cmap=\"tab10\")\n",
    "ax.set_title(\"Principal Components\")\n",
    "ax.set_xlabel(\"PC 0\")\n",
    "ax.set_ylabel(\"PC 1\")\n",
    "ax.set_zlabel(\"PC 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "shuffled = random.sample(list(zip(latent, labels)), len(latent))\n",
    "train = shuffled[len(shuffled) // 4:]\n",
    "test = shuffled[:len(shuffled) // 4]\n",
    "\n",
    "train_feats = [t[0] for t in train]\n",
    "train_labels = [t[1] for t in train]\n",
    "\n",
    "test_feats = [t[0] for t in test]\n",
    "test_labels = [t[1] for t in test]\n",
    "\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Create a Classifier object\n",
    "quality_model = RandomForestClassifier()\n",
    "\n",
    "# Create a model that classifies quality of wines based on many features\n",
    "result = quality_model.fit(train_feats, train_labels)\n",
    "\n",
    "## 6. Run the model on the training data\n",
    "train_predicted = quality_model.predict(train_feats)\n",
    "\n",
    "## 7. Measure error\n",
    "accuracy_score(train_labels, train_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Run the model on the training data\n",
    "test_predicted = quality_model.predict(test_feats)\n",
    "\n",
    "## 7. Measure error\n",
    "accuracy_score(test_labels, test_predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "9103",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
